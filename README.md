# 🌾 GAN-Model-For-Estimate-Cultivated-Areas-of-Strategic-Crops

## 🔍 Project Overview

This project aims to **detect and refine field boundaries in agricultural land** using a custom-designed **Generative Adversarial Network (GAN)**. The GAN is trained to perform two core tasks:

1. **Denoise and post-process** noisy field boundary masks generated by earlier image processing pipelines.
2. **Generate augmented data** to expand the dataset for training downstream segmentation models.

Due to the **natural variability of agricultural environments**, our dataset is limited to **~60 high-resolution satellite/drone images**. Each data sample consists of:
- A **preprocessed noisy mask** (initial estimate),
- A **hand-drawn ground truth mask** (clean target),
- The **original clean RGB image** (reference input).

This setup allows the GAN to learn a mapping from distorted, noisy inputs to clean, ground-truth-aligned field boundaries, supporting both quality enhancement and synthetic data generation.
## 📁 Dataset Structure
<pre> <code> dataset/ 
  ├── clean/ # Ground-truth manually labeled masks 
  ├── noisy/ # Noisy masks (GAN input) 
  └── original/ # Optional: raw clean RGB images (visualization) </code> </pre>

Each file is matched by name across all folders, e.g.:
<pre><code>noisy/img_001.png
clean/img_001.png
original/img_001.png</code> </pre>

All images are grayscale, resized to 256×256, and normalized for model input.

## 🧠 Model Architecture

This project uses a **fully connected GAN** architecture:

- The **Generator** is composed of a series of linear layers with ReLU activations, taking a noisy image and outputting a denoised mask.
- The **Discriminator** evaluates whether an input mask is real (from the ground truth) or fake (from the generator), using LeakyReLU layers and a sigmoid output.

> 🧱 Below is a 3D visual representation of the GAN architecture used in this project:
![ChatGPT Image Jun 29, 2025, 01_06_50 AM](https://github.com/user-attachments/assets/86d24f56-ae12-4d36-83d2-9a389e9025b2)


## 🏋️ Training Details

- **Framework**: PyTorch  
- **Input size**: 1 × 256 × 256 grayscale images  
- **Loss Function**: Binary Cross Entropy (BCEWithLogitsLoss)  
- **Optimizer**: Adam (learning rate = 0.0005, betas = (0.5, 0.999))  
- **Epochs**: 400  
- **Batch size**: 16  
- **Augmentations**: random rotation, flipping (horizontal/vertical)

The Generator is trained to minimize the difference between generated and clean masks, while the Discriminator learns to distinguish between real and generated samples. Training alternates between updating both networks in typical adversarial fashion.

## 🖼 Sample Results

![image_2025-06-29_00-54-50](https://github.com/user-attachments/assets/03e82e65-e0d9-4a97-9587-9206c80063c7)


